
# ğŸ¾ Lost Pet Dataset AI Analysis & Search Platform

A Flask-based AI-powered web platform for analyzing and searching lost pet data.  
This project combines structured evaluation with Gemini API to enhance pet recovery efforts through intelligent recommendations and interactive filtering.

---

## ğŸ“ Dataset Description

The main dataset is in `CSV` format (`petLoss.csv`) with the following fields:

- `æ™¶ç‰‡è™Ÿç¢¼` (Chip number)  
- `å¯µç‰©å` (Pet name)  
- `å¯µç‰©åˆ¥`, `æ€§åˆ¥` (Pet type & gender)  
- `å“ç¨®` (Breed)  
- `æ¯›è‰²` (Color)  
- `å¤–è§€`, `ç‰¹å¾µ` (Appearance, features)  
- `éºå¤±æ™‚é–“`, `éºå¤±åœ°é»` (Lost time & location)  
- `é£¼ä¸»å§“å`, `é€£çµ¡é›»è©±`, `Email`  
- `PICTURE` (Image link)

---

## ğŸ¤– AI Analysis: `pet_analyzer.py`

### Analysis Targets (Gemini)

Each record is evaluated on the following criteria:

- æ˜¯å¦æä¾›å…·é«”ä¸”è©³ç´°çš„éºå¤±åœ°é»ï¼ˆæ˜¯å¦å…·é«”ï¼‰
- æ¯›è‰²èˆ‡å¤–è§€æè¿°æ˜¯å¦è¶³å¤ è¾¨è­˜
- æ˜¯å¦æœ‰æ˜é¡¯çš„å€‹åˆ¥ç‰¹å¾µï¼ˆå¦‚æ–·å°¾ã€ç•°è‰²çœ¼ï¼‰
- éºå¤±æ™‚é–“æ˜¯å¦æ˜ç¢ºï¼ˆæœ‰æ—¥æœŸèˆ‡æ™‚é–“ï¼‰
- æ˜¯å¦æœ‰æ¸…æ™°åœ–ç‰‡
- æ˜¯å¦é©åˆå…¬å‘Š
- å»ºè­°è£œå……å“ªäº›è³‡è¨Šï¼ˆä¾‹å¦‚å€‹æ€§ã€æ˜¯å¦çµç´®ï¼‰

### Prompt Strategy

- The script constructs a batch prompt to Gemini API with 100 records per request.
- Responses are structured CSV strings separated by delimiters.
- Each result is parsed and written to new CSV output.

### Input / Output

- Input:
  - `petLoss.csv` or split files: `loss1.csv`, `loss2.csv`, ...
- Output:
  - `pet_batch_output1.csv`, `pet_batch_output2.csv`, ...

---

## ğŸŒ Web Interface: `app.py`

Built with Flask, the web interface provides:

- File loading via `?file=pet_batch_output1.csv`
- Merge with `loss1.csv` for full context
- Filtering based on AI-evaluated fields
- Additional manual search:
  - ğŸ” Chip number or pet name keyword
  - ğŸ§  AI-assisted feature search via Gemini

### Web Features

- Sort by completeness score (based on AI fields)
- Search and filter simultaneously
- Easy data browsing and review

---

## ğŸ§ª How to Use

### Step 1ï¸âƒ£ â€“ Split the Dataset  
Split the original file into chunks of 1000 records:  
```bash
python pet_analyzer.py split
```

### Step 2ï¸âƒ£ â€“ Analyze All Files  
Batch process all split files using Gemini:  
```bash
python pet_analyzer.py
```

### Step 3ï¸âƒ£ â€“ Analyze a Specific File  
Analyze a single CSV file:  
```bash
python pet_analyzer.py loss1.csv
```

### Step 4ï¸âƒ£ â€“ Start the Flask Web App  
```bash
python app.py
```

### Step 5ï¸âƒ£ â€“ Open in Browser  
```
http://127.0.0.1:5000/?file=pet_batch_output*.csv
```
- * is series number of batch data.

### Step 6ï¸âƒ£ â€“ View Help  
```bash
python pet_analyzer.py help
```

---

## ğŸ–¼ï¸ Demo Screenshot

![Demo](https://github.com/41171119H/Data-Structure/blob/main/autogen/petLoss/petLossDemo.png)

